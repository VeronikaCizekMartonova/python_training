{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb09953",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "### 1. Register at kaggle.com (largest online community of data scientists, feel free to explore it)\n",
    "### 2. Download the train.csv from <a href=\"https://www.kaggle.com/c/titanic\" title=\"https://www.kaggle.com/c/titanic\">https://www.kaggle.com/c/titanic</a> (beginner exercise to get started with ML)\n",
    "### 3. Clean and prepare the data for modeling (use what you learned from the previous exercise, explain any changes you had to make for modeling)\n",
    "### 4. Split the data into training and testing (explain why we do this):\n",
    "    \n",
    "* Data in our dataset is labeled, new data will be unknown.\n",
    "* Avoiding the phenomena of “overfitting” (it means that is an instance where a machine learning model fits its training data too well and fails to reliably fit additional data).\n",
    "* The volume of the testing group is usually 1/5 from the original dataset.\n",
    "* Problems with a small dataset:\n",
    "    * it is problem to prevent overfitting and therefore the small group is divided into testing and training groups multiple times.\n",
    "    \n",
    "### 5. Explain Logistic Regression:\n",
    "* __Overview:__\n",
    "    * Logistic regression is one of the simplest and most used machine learning algorithms for class classification – in our case: how big is the probability that a person will survive based on characteristic as sex, age, purchased ticket, etc…\n",
    "* __Math behind Logistic Regression:__\n",
    "     * Comparison of Linear Regression with the Logistic Regression:\n",
    "        * __Linear Regression:__\n",
    "            * We use linear regression to predict the dependent variable on the independent variable, e.g., we have 5 mice, and we know their weight and size (the red points in the graph in the picture below). And we want to predict how big will be the sixth mouse if we know what her weight is. Notice the independent variable is weight and the dependent variable is the size of the mouse in our case.\n",
    "            * To gain this value (or if you want prediction) we have to do three main things: Firstly, calculate the $R^2$ and determine if the weight and size are correlated. Then calculate a p-value to determine if the $R^2$ value is statistically significant and then use the line to predict the size given weight.\n",
    "            * It means that we need to interpolate the points in the graph by linear line. If we gain this line, we can predict the size given weight as it is shown in the picture below.\n",
    "            <img src=\"https://drive.google.com/uc?export=view&id=1PQ99A7jrHeoOoRQYhYD5yAhoLDIfLt4B\" width=\"400\">\n",
    "        * __Logistic Regression:__\n",
    "            * Logistic regression is similar to linear regression, except logistic regression predicts whether something is true or false (instead of predicting something continuous). In our case with mice – if the mouse is obese or not.\n",
    "            * And, instead of fitting a linear line to the data, logistic regression fits the sigmoid or the “S” shaped function, and the “S” curve goes from 0 (not obese) to 1 (is obese). It means that the curve tells us the probability that the mouse is obese based on its weight.\n",
    "            * If we take a mouse with high weight, there is a big probability that the new mouse is obese. If we take a mouse with a medium weight there will be a 50% probability that the mouse will be obese and as a last example if we chose a mouse with low weight, it would not be obese (see the picture below).\n",
    "            <img src=\"https://drive.google.com/uc?export=view&id=1i8IIZVU8nmzWWHyXZmvGrSVx7FyZ5ybf\" width=\"max\">\n",
    "            \n",
    "     * One big difference between linear regression and logistic regression is how the line is fitted to the data. With linear regression, we fit the line using “least squares”. In other words, we find the line that minimizes the sum of the squares of these residuals. We also use the residuals to calculate the R square and to compare simple models to complicated models. Logistic regression does not have the concept of residuals. Instead, it uses “maximum likelihood estimation”. We interpolate the points in the graph by “S” curves and for each of them we calculate the likelihood of the data by special formula and then we pick up the ”S” curve with the maximal value of likelihood.\n",
    "     <img src=\"https://drive.google.com/uc?export=view&id=1e_vFByT0UL7l1v1wlRfQtZik-g_OOJ2q\" width=\"300\">\n",
    "* __The basic logistic regression equation:__ \n",
    "\n",
    "    The basic logistic regression equation is following:\n",
    "### $$ y = \\dfrac{1}{1 - e^{-(w_0 + w_i x)}}, $$\n",
    "    where $y$ is predicted probability of belonging to the default class, $x$ is feature vector (input variable - for the mice it was the weight but we can have more than one characteristics and therefore it is the vector and we call it feature vector in machine learning), $w_0$ is bias term, $w_i$ is weight for the feature vector $x$. \n",
    "    The right part of the formula above $\\dfrac{1}{1 - e^{-(w_0 + w_i x)}}$ is prescript of the sigmoid function and $(w_0 + w_i x)$ is the linear model within the logistic regression.\n",
    "    \n",
    "    We have to determine the bias coefficient and weight coefficient(s) for gaining the probability of belonging to the default class.\n",
    "\n",
    "* __Types of Logistic Regression + use cases:__\n",
    "    1. Binary logistic regression: The response variable can only belong to one of two categories.\n",
    "         * Use cases \n",
    "              * Spam detection – the email is spam or not\n",
    "              * Draft to NHL – the hockey player will be drafted or not\n",
    "              * Obese prediction – the person will be obese or not\n",
    "    2.\tMultinomial logistic regression: The response variable can belong to one of three or more categories and there is no natural ordering among the categories.\n",
    "          * Use cases \n",
    "               * Political preferences – Suppose a political scientist wants to use the predictor variables annual income and years of education to predict the probability that an individual will vote for one of the presidential candidates.\n",
    "    3.\tOrdinal logistic regression: The response variable can belong to one of three or more categories and there is a natural ordering among the categories.\n",
    "          * Use cases \n",
    "               * Olympic medals - Suppose a bookmaker wants to use the variables age, height, and nationality to predict the probability that an individual athlete wins a gold medal in an Olympic sport.\n",
    "               * Movie rating – Suppose a movie critic wants to use the predictor variables total run time and (the genre to predict the probability that a given movie will be receiving a rating between 1 and 10.\n",
    "\n",
    "* __Logistic regression assumptions:__\n",
    "    1. Dependent variable has to be binary\n",
    "    2. Observations have to be independent of each other\n",
    "    3. Absence of multicollinearity\n",
    "    4. Linearity of independent variables and log likelihood\n",
    "* __Best practices:__\n",
    "    * Big data set and balanced data set (data set with normal distribution).\n",
    "    * Simple model - it is good to have the simplest model as possible because we want to prevent unexpected behavior.\n",
    "\n",
    "### 6. Create a LR model to predict who survived (a simple model using scikit-learn, feel free to try out different libraries as well)\n",
    "I deal with the data set according the youtube tutorial:  <a href=\"https://www.youtube.com/watch?v=fATVVQfFyU0\" title=\"https://www.youtube.com/watch?v=fATVVQfFyU0\">https://www.youtube.com/watch?v=fATVVQfFyU0</a> and <a href=\"https://www.youtube.com/watch?v=9koIuiYqjBU\" title=\"https://www.youtube.com/watch?v=9koIuiYqjBU\">https://www.youtube.com/watch?v=9koIuiYqjBU</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36a3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I deal with the data set according the youtube tutorial: https://www.youtube.com/watch?v=fATVVQfFyU0.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "import sklearn #scikit learn library for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d76294",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'train.csv'\n",
    "try:\n",
    "    sheet = pd.read_csv(file_name,header=0,encoding='utf-8') # key is PassengerId\n",
    "except FileNotFoundError:\n",
    "    print('The csv file %s has not been found.' %file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26aa9c65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d191eac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VeronikaČížekMártono\\AppData\\Local\\Temp\\ipykernel_10948\\1576733875.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  sns.heatmap(sheet.corr(),cmap=\"YlGnBu\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking for the positive and negative correlation in the data\n",
    "sns.heatmap(sheet.corr(),cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b94230dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data into training and testing data - I do almost as a first thing because I dont want to be biased. \n",
    "# We use the function StratifiedShuffleSplit to gain the balanced training dataset (data set with balanced classes)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size = 0.2)\n",
    "for train_indices, test_indices in split.split(sheet,sheet[[\"Survived\",\"Pclass\",\"Sex\"]]):\n",
    "    strat_train_set = sheet.loc[train_indices]\n",
    "    strat_test_set = sheet.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5d99cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train group from train data set: (712, 12)\n",
      "The test group from train data set: (179, 12)\n",
      "The original train data set: (891, 12)\n"
     ]
    }
   ],
   "source": [
    "#1. check - the volume of training and testing group:\n",
    "print (\"The train group from train data set:\",strat_train_set.shape)\n",
    "print (\"The test group from train data set:\",strat_test_set.shape)\n",
    "print (\"The original train data set:\",sheet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160b7b95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chibnall, Mrs. (Edith Martha Bowerman)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113505</td>\n",
       "      <td>55.0000</td>\n",
       "      <td>E33</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Miss. Emily Borie</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Harper, Mr. Henry Sleeper</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17572</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D33</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Cohen, Mr. Gurshon \"Gus\"</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 3540</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Badt, Mr. Mohamed</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2623</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rekic, Mr. Tido</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349249</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bryhl, Mr. Kurt Arnold Gottfrid</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>236853</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Morley, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>364506</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Staneff, Mr. Ivan</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349208</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Saalfeld, Mr. Adolphe</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19988</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>C106</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                    Name  \\\n",
       "166          167         1       1  Chibnall, Mrs. (Edith Martha Bowerman)   \n",
       "311          312         1       1              Ryerson, Miss. Emily Borie   \n",
       "645          646         1       1               Harper, Mr. Henry Sleeper   \n",
       "204          205         1       3                Cohen, Mr. Gurshon \"Gus\"   \n",
       "661          662         0       3                       Badt, Mr. Mohamed   \n",
       "..           ...       ...     ...                                     ...   \n",
       "108          109         0       3                         Rekic, Mr. Tido   \n",
       "728          729         0       2         Bryhl, Mr. Kurt Arnold Gottfrid   \n",
       "461          462         0       3                     Morley, Mr. William   \n",
       "76            77         0       3                       Staneff, Mr. Ivan   \n",
       "298          299         1       1                   Saalfeld, Mr. Adolphe   \n",
       "\n",
       "        Sex   Age  SibSp  Parch    Ticket      Fare            Cabin Embarked  \n",
       "166  female   NaN      0      1    113505   55.0000              E33        S  \n",
       "311  female  18.0      2      2  PC 17608  262.3750  B57 B59 B63 B66        C  \n",
       "645    male  48.0      1      0  PC 17572   76.7292              D33        C  \n",
       "204    male  18.0      0      0  A/5 3540    8.0500              NaN        S  \n",
       "661    male  40.0      0      0      2623    7.2250              NaN        C  \n",
       "..      ...   ...    ...    ...       ...       ...              ...      ...  \n",
       "108    male  38.0      0      0    349249    7.8958              NaN        S  \n",
       "728    male  25.0      1      0    236853   26.0000              NaN        S  \n",
       "461    male  34.0      0      0    364506    8.0500              NaN        S  \n",
       "76     male   NaN      0      0    349208    7.8958              NaN        S  \n",
       "298    male   NaN      0      0     19988   30.5000             C106        S  \n",
       "\n",
       "[179 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. check - we can see that the testing data set is mixed\n",
    "strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616edc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2. check - it is good to look to the distribution of training and testing groups-from the charts we see that the distribution is similar\n",
    "plt.subplot(1,2,1)\n",
    "strat_train_set[\"Survived\"].hist() ## blue bars\n",
    "strat_train_set[\"Pclass\"].hist() ## orange bars\n",
    "#strat_train_set[\"Sex\"].hist()\n",
    "plt.subplot(1,2,2)\n",
    "strat_test_set[\"Survived\"].hist()\n",
    "strat_test_set[\"Pclass\"].hist()\n",
    "#strat_test_set[\"Sex\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e658d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 136 to 838\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  712 non-null    int64  \n",
      " 1   Survived     712 non-null    int64  \n",
      " 2   Pclass       712 non-null    int64  \n",
      " 3   Name         712 non-null    object \n",
      " 4   Sex          712 non-null    object \n",
      " 5   Age          565 non-null    float64\n",
      " 6   SibSp        712 non-null    int64  \n",
      " 7   Parch        712 non-null    int64  \n",
      " 8   Ticket       712 non-null    object \n",
      " 9   Fare         712 non-null    float64\n",
      " 10  Cabin        165 non-null    object \n",
      " 11  Embarked     711 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 72.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# 1. problem:\n",
    "# from the info we can see that we are missing some age value - we have to deal with it and we are missing a lot of cabin values\n",
    "\n",
    "strat_train_set.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "751977d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with the missing age data - replacing the null values with the means value\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer ## for the null values - we will input the cell with some value (in uor case mean)\n",
    "class AgeImputer(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def fit(self,x,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        imputer = SimpleImputer(strategy=\"mean\")\n",
    "        X[\"Age\"] = imputer.fit_transform(X[[\"Age\"]])\n",
    "        X[\"Fare\"] = imputer.fit_transform(X[[\"Fare\"]])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69bd63ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usually we need the strings replace by binary numbers (e.g. \"sex\", \"Embarked\" ) --> we dont want to have C, S, Q but we want to have \n",
    "# three new columns C,S,Q with values 0 or 1\n",
    "# I do it to construct the feature vector which should contain the numeric values. It means I encode e.g. string values\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class FeatureEncoder(BaseEstimator,TransformerMixin):\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform (self,X):\n",
    "        encoder = OneHotEncoder()\n",
    "        \n",
    "        matrix = encoder.fit_transform(X[[\"Embarked\"]]).toarray()\n",
    "        column_names = [\"C\",\"S\", \"Q\",\"N\"]\n",
    "        \n",
    "        for i in range(len(matrix.T)):\n",
    "            X[column_names[i]] = matrix.T[i] #swaping the axes\n",
    "        \n",
    "        matrix = encoder.fit_transform(X[[\"Sex\"]]).toarray()\n",
    "        column_names = [\"Female\",\"Male\"]\n",
    "        \n",
    "        for i in range(len(matrix.T)):\n",
    "            X[column_names[i]] = matrix.T[i] #swaping the axes\n",
    "            \n",
    "        return X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b01d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last class prepared to deal with the data is the dropper. \n",
    "class FeatureDropper(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return X.drop([\"Embarked\", \"Name\",\"Ticket\",\"Cabin\",\"Sex\",\"N\"], axis=1, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a33bd570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([(\"ageimputer\", AgeImputer()),\n",
    "                     (\"featureencoder\",FeatureEncoder()),\n",
    "                     (\"featuredropper\",FeatureDropper())])\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d80c80",
   "metadata": {},
   "source": [
    "### Processing of Training data (training group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88ce683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set = pipeline.fit_transform(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf25d2b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.696478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>835</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>775</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.696478</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29.696478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>428</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>839</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.4958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass        Age  SibSp  Parch     Fare    C  \\\n",
       "136          137         1       1  19.000000      0      2  26.2833  0.0   \n",
       "276          277         0       3  45.000000      0      0   7.7500  0.0   \n",
       "407          408         1       2   3.000000      1      1  18.7500  0.0   \n",
       "168          169         0       1  29.696478      0      0  25.9250  0.0   \n",
       "834          835         0       3  18.000000      0      0   8.3000  0.0   \n",
       "..           ...       ...     ...        ...    ...    ...      ...  ...   \n",
       "774          775         1       2  54.000000      1      3  23.0000  0.0   \n",
       "863          864         0       3  29.696478      8      2  69.5500  0.0   \n",
       "36            37         1       3  29.696478      0      0   7.2292  1.0   \n",
       "427          428         1       2  19.000000      0      0  26.0000  0.0   \n",
       "838          839         1       3  32.000000      0      0  56.4958  0.0   \n",
       "\n",
       "       S    Q  Female  Male  \n",
       "136  0.0  1.0     1.0   0.0  \n",
       "276  0.0  1.0     1.0   0.0  \n",
       "407  0.0  1.0     0.0   1.0  \n",
       "168  0.0  1.0     0.0   1.0  \n",
       "834  0.0  1.0     0.0   1.0  \n",
       "..   ...  ...     ...   ...  \n",
       "774  0.0  1.0     1.0   0.0  \n",
       "863  0.0  1.0     1.0   0.0  \n",
       "36   0.0  0.0     0.0   1.0  \n",
       "427  0.0  1.0     1.0   0.0  \n",
       "838  0.0  1.0     0.0   1.0  \n",
       "\n",
       "[712 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf5fec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 136 to 838\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  712 non-null    int64  \n",
      " 1   Survived     712 non-null    int64  \n",
      " 2   Pclass       712 non-null    int64  \n",
      " 3   Age          712 non-null    float64\n",
      " 4   SibSp        712 non-null    int64  \n",
      " 5   Parch        712 non-null    int64  \n",
      " 6   Fare         712 non-null    float64\n",
      " 7   C            712 non-null    float64\n",
      " 8   S            712 non-null    float64\n",
      " 9   Q            712 non-null    float64\n",
      " 10  Female       712 non-null    float64\n",
      " 11  Male         712 non-null    float64\n",
      "dtypes: float64(7), int64(5)\n",
      "memory usage: 72.3 KB\n"
     ]
    }
   ],
   "source": [
    "strat_train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45be2d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step - we want to have numpy array from the df, so we transform them:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = strat_train_set.drop([\"Survived\"],axis=1)\n",
    "y = strat_train_set[\"Survived\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_data_train_set = scaler.fit_transform(X)\n",
    "y_data_train_set = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3001a64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.21737852, -1.56828591, -0.82648564, ...,  0.6336993 ,\n",
       "         1.35941164, -1.35941164],\n",
       "       [-0.67124185,  0.82789342,  1.18245851, ...,  0.6336993 ,\n",
       "         1.35941164, -1.35941164],\n",
       "       [-0.16021397, -0.37019624, -2.06275896, ...,  0.6336993 ,\n",
       "        -0.73561236,  0.73561236],\n",
       "       ...,\n",
       "       [-1.60747614,  0.82789342,  0.        , ..., -1.57803551,\n",
       "        -0.73561236,  0.73561236],\n",
       "       [-0.08219445, -0.37019624, -0.82648564, ...,  0.6336993 ,\n",
       "         1.35941164, -1.35941164],\n",
       "       [ 1.52110678,  0.82789342,  0.17798643, ...,  0.6336993 ,\n",
       "        -0.73561236,  0.73561236]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final set of feature vectors\n",
    "X_data_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c8f7de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final set of labes for each feature vector (fro each person)\n",
    "y_data_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d199f",
   "metadata": {},
   "source": [
    "### Processing of Training data (testing group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb5405c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set = pipeline.fit_transform(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20099e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.709128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>662</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.709128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.709128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass        Age  SibSp  Parch      Fare    C  \\\n",
       "166          167         1       1  29.709128      0      1   55.0000  0.0   \n",
       "311          312         1       1  18.000000      2      2  262.3750  1.0   \n",
       "645          646         1       1  48.000000      1      0   76.7292  1.0   \n",
       "204          205         1       3  18.000000      0      0    8.0500  0.0   \n",
       "661          662         0       3  40.000000      0      0    7.2250  1.0   \n",
       "..           ...       ...     ...        ...    ...    ...       ...  ...   \n",
       "108          109         0       3  38.000000      0      0    7.8958  0.0   \n",
       "728          729         0       2  25.000000      1      0   26.0000  0.0   \n",
       "461          462         0       3  34.000000      0      0    8.0500  0.0   \n",
       "76            77         0       3  29.709128      0      0    7.8958  0.0   \n",
       "298          299         1       1  29.709128      0      0   30.5000  0.0   \n",
       "\n",
       "       S    Q  Female  Male  \n",
       "166  0.0  1.0     1.0   0.0  \n",
       "311  0.0  0.0     1.0   0.0  \n",
       "645  0.0  0.0     0.0   1.0  \n",
       "204  0.0  1.0     0.0   1.0  \n",
       "661  0.0  0.0     0.0   1.0  \n",
       "..   ...  ...     ...   ...  \n",
       "108  0.0  1.0     0.0   1.0  \n",
       "728  0.0  1.0     0.0   1.0  \n",
       "461  0.0  1.0     0.0   1.0  \n",
       "76   0.0  1.0     0.0   1.0  \n",
       "298  0.0  1.0     0.0   1.0  \n",
       "\n",
       "[179 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "925ac8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step - we want to have numpy array from the df, so we transform them:\n",
    "\n",
    "X = strat_test_set.drop([\"Survived\"],axis=1)\n",
    "y = strat_test_set[\"Survived\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_data_test_set = scaler.fit_transform(X)\n",
    "y_data_test_set = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f99f35e",
   "metadata": {},
   "source": [
    "## Model LR on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "938cf7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model of Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV  \n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_data_train_set, y_data_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ba1a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1\n",
      " 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0\n",
      " 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1\n",
      " 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1\n",
      " 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 0 1 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 1 0\n",
      " 0 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 1 0 0\n",
      " 0 1 0 1 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1\n",
      " 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1\n",
      " 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1\n",
      " 0 1 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 0 1\n",
      " 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 1 1 0 0\n",
      " 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0\n",
      " 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Training data (training group)\n",
    "X_train_prediction = model.predict(X_data_train_set) \n",
    "print(X_train_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb797cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of training data: 0.7991573033707865\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of prediction on Training data (training group)\n",
    "training_data_accuracy = sklearn.metrics.accuracy_score(y_data_train_set,X_train_prediction)\n",
    "print(\"Accuracy score of training data:\",training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4e140f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 1 0 0 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0\n",
      " 1 0 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Training data (testing group)\n",
    "X_test_prediction = model.predict(X_data_test_set) \n",
    "print(X_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07b0b9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of testing data: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of prediction on Training data (testing group)\n",
    "testing_data_accuracy = sklearn.metrics.accuracy_score(y_data_test_set,X_test_prediction)\n",
    "print(\"Accuracy score of testing data:\",testing_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b56407d",
   "metadata": {},
   "source": [
    "### 7. Evaluate your model using the testing data\n",
    "#### __A. Why do we evaluate models?__ </li>\n",
    "We need to evaluate model to find out how \"good\" is our model and if it is possible to use it for prediction.\n",
    "\n",
    "#### __B. Overview on different metrics with math behind them__\n",
    "* Courtesy of https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html and https://medium.com/@nandinisekar27/logistic-regression-overview-and-its-error-metrics-8b54512ca39f and https://www.keboola.com/blog/logistic-regression-machine-learning\n",
    "* __What are Classification Metrics?__\n",
    "    * Classification is about predicting a label and then identifying which category an object belongs to based on different parameters. \n",
    "    * In order to measure how well our classification model is doing at making these predictions, we use classification metrics. It measures the performance of our machine learning model, giving us the confidence that these outputs can be further used in decision-making processes. \n",
    "    * The performance is normally presented in a range from 0 to 1, where a score of 1 represents perfection. \n",
    "    \n",
    "* __Problems with the threshold__ \n",
    "    * If we use a range from 0 to 1 to represent the performance of our model, what happens when the value is 0.5? As we know from early math classes, if the probability is greater than 0.5, we round it up to 1 (positive) - if not, it is 0 (negative).\n",
    "    * That sounds okay, but now when you are using classification models to help determine the output of real-life cases. We need to be 100% sure that the output has been correctly classified.\n",
    "    * For example, logistic regression is used to detect spam emails. If the probability that the email is spam is based on the fact that it is above 0.5, this can be risky as we could potentially direct an important email into the spam folder. The want and need for the performance of the model to be highly accurate becomes more sensitive for health-related and financial tasks.\n",
    "    * Therefore, using the threshold concept of values above the threshold value tend to be 1, and a value below the threshold value tends to be 0 can cause challenges.\n",
    "    * Although there is the option to adjust the threshold value, it still raises the risk that we classify incorrectly. For example, having a low threshold will classify the majority of positive classes correctly, but within the positive will contain negative classes - vice versa if we had a high threshold.\n",
    "    \n",
    "* __Classification metrics__ \n",
    "    * __Accuracy__\n",
    "         * It’s the one that’s typically used the most, especially for beginners. \n",
    "         * Accuracy is defined as the number of correct predictions over the total predictions: \n",
    "         \n",
    "         $$ Accuracy = \\dfrac{correct \\, predictions}{total \\, predictions}$$\n",
    "         \n",
    "         * However, we can further expand on this using these:\n",
    "             * True Positive $(TP)$ - you predicted positive and it’s actually positive \n",
    "             * True Negative $(TN)$ - you predicted negative and it’s actually negative\n",
    "             * False Positive $(FP)$ - you predicted positive and it’s actually negative\n",
    "             * False Negative $(FN)$ - you predicted negative and it’s actually positive \n",
    "             \n",
    "         * So we can say the true predictions are $TN+TP$, while the false prediction is $FP+FN$. The equation can now be redefined as:\n",
    "         \n",
    "         $$ Accuracy = \\dfrac{TP + TN}{TP + TN + FP + FN}$$\n",
    "    * __Confusion Matrix__         \n",
    "         * Confusion Matrix below is used to find the amount of values which are predicted correctly & wrongly          \n",
    "         <img src=\"https://drive.google.com/uc?export=view&id=1CCGUmwQjfe0T59pa_6g6eCkMRY3ar1Ck\" width=\"700\">\n",
    "   \n",
    "    * __Precision and Recall + F1 Score__\n",
    "         * If we want to further test the “accuracy” in different classes where we want to ensure that when the model predicts positive, it is in fact true positive - we use precision. We can also call this Positive Prediction Value which can be defined as:\n",
    "         \n",
    "         $$ Precision = \\dfrac{TP}{TP + FP}$$         \n",
    "\n",
    "        * If we want to further test the “accuracy” in different classes where we want to ensure that when the model predicts negative, it actually is negative - we use recall. Recall is the same formula as sensitivity and can be defined as:\n",
    "        \n",
    "         $$ Recall = \\dfrac{TP}{TP + FN}$$ \n",
    "     \n",
    "        * Using both precision and recall are useful metrics when there is an imbalance in the observations between the two classes. For example, there are more of one class (1) and only a few of the other class (0) in the dataset.\n",
    "        * In order to increase the precision of your model, you will need to have fewer $FP$ and not have to worry about the $FN$. Whereas, if you want to increase recall, you will need to have fewer $FN$ and not have to worry about the $FP$.\n",
    "        * Raising the classification threshold reduces false positives - increasing precision. Raising the classification threshold reduces true positives or keeps them the same, whilst increasing false negatives or keeps them the same. - decreasing recall or keeping it constant.\n",
    "        * Unfortunately, it’s not possible to have a high precision and recall value. If you increase precision, it will reduce recall - vice versa. This is known as the precision/recall tradeoff.\n",
    "\n",
    "         * F1 Score: This is defined as Harmonic mean between Precision and Recall values\n",
    "        \n",
    "         $$ F1 = 2 \\dfrac{Precision \\,x\\, Recall}{Precision \\,+\\, Recall}$$ \n",
    "         \n",
    "    * __ROC Curve__         \n",
    "         * It plots the false positive rate (x-axis) against the true positive rate (y-axis).\n",
    "\n",
    "          $$ True \\,Positive \\,Rate = \\dfrac{TP}{TP \\,+\\, FN} $$\n",
    "          \n",
    "          $$ False \\,Positive \\,Rate = \\dfrac{FP}{FP \\,+\\, TN} $$\n",
    "         * The true positive rate is also known as sensitivity, and the false positive rate is also known as the inverted specificity rate. \n",
    "\n",
    "          $$ Specificity = \\dfrac{TN}{TN \\,+\\, FP} $$\n",
    " \n",
    "         * If the values on the x-axis consist of smaller values, this indicates lower FP and higher TN. If the values on the y-axis consist of larger values, this indicates higher TP and lower FN.\n",
    "\n",
    "         * The ROC presents the performance of a classification model at all classification thresholds, like this:  \n",
    "         \n",
    "              <img src=\"https://drive.google.com/uc?export=view&id=1MSzfO8sTlHry8B1t_vd3dGVo508klu-0\" width=\"500\">\n",
    "              \n",
    "    * __AUC ROC Curve__              \n",
    "         * When it comes to the ROC curve, you may have also heard Area Under the Curve (AUC). It’s exactly what it says it is - the area under the curve. If you want to know how good your curve is, you calculate the ROC AUC score. AUC measures the performance across all possible classification thresholds.\n",
    "\n",
    "         * The more area under the curve you have, the better - the higher the ROC AUC score. This is when the FN and FP are both at zero - or if we refer to the graph above, it’s when the true positive rate is 1 and the false positive rate is 0. \n",
    "\n",
    "\n",
    "#### __C. What kind of metrics are suitable in this case?__\n",
    "* Generally, our goal is to increase the number of TP and TN, to gain better results. And what to do with False Negatives and False positives? We can approach them differently in different cases:\n",
    "    * __e.g.: disease - people who were tested for cancer__:\n",
    "        * __we case about False Negative__ - we gain a group of people who are not suspected of cancer but they can have cancer\n",
    "        * __we do not care about False Positives__ - the result of the test is that some people are positived tested for cancer but do not have cancer - we can send them to other tests and we find out that these persons are healthy.\n",
    "* When it comes to __Precision we care about lowering the FP and for recall we care about lowering the FN.__ However, there is a metric that we can use to __lower both the FP and FN - ROC curve__.\n",
    "\n",
    "\n",
    "#### __D. Are you satisfied with the results? How can you improve your model?__\n",
    "\n",
    "There are multiple methods that can be used to improve your logistic regression model.\n",
    "\n",
    "* __Data preprocessing__\n",
    "    * The greatest improvements are usually achieved with a proper data cleaning process. Logistic regression uses a linear model, so it suffers from the same issues that linear regression does. To properly prepare the data for logistic regression modeling, you need to:\n",
    "\n",
    "        * __Remove outliers.__ Outliers will skew your model to perform less well. \n",
    "        * __Remove multicollinearity.__ Logistic regression assumes that the predictor variables (features) are not correlated with one another. Check their pairwise correlation and from the analysis, remove those variables which are highly correlated.\n",
    "        * __Assert linear assumption.__ If your independent variables do not have a linear relationship with your predictor variable, you need to log transform them to reshape polynomial relationships into linear. \n",
    "        * __Assert normal distribution.__ The model assumes that the independent variables follow a Gaussian distribution. Transform your variables with log transform or BoxCox if they are not normally distributed.\n",
    "    * Logistic regression has additional assumptions and needs for cleaning:\n",
    "\n",
    "        * __Binary output variable.__ Transform your output variable into 0 or 1.\n",
    "        * __Failure to converge.__ The maximum likelihood estimation model (the ‘maths’) behind logistic regression assumes that no single variable will perfectly predict class membership. In the event that you have a feature that perfectly predicts the target class, the algorithm will try to assign it infinite weights (because it is so important) and thus will fail to converge to a solution. If you have a perfect predictor, simply remove it from the feature set... or just don’t model your data at all. At the end of the day, you do not need a machine learning model if you have a perfect predictor.\n",
    "* Feature scaling\n",
    "    * Feature values can be comparably different by orders of magnitude. For instance, loan size is in the tens of thousands (50,000), while “number of months late” is in single digits (0, 1, 2, …).  \n",
    "    * Features of different scales convert slower (or not at all) with gradient descent. \n",
    "    * Normalize and standardize your features to speed up and improve model training.\n",
    "* Regularization\n",
    "    * Regularization is particularly useful in settings with multiple features (or independent variables). Regularization takes a complex model (with multiple predictors) and sets their weights to zero (L1 regularization). This effectively removes a predictor from the linear equation or lowers its weights towards zero (L2 regularization), making the feature less impactful on the final logistic regression equation.\n",
    "    * Both of these approaches work great when you have an overly complex model which overfits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c640c548",
   "metadata": {},
   "source": [
    "### Evaluation of my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "132653b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a84ff35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of CM:\n",
      "True Negative || False Negative \n",
      "False Positive || True Positive\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAHHCAYAAAD58fFKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMsUlEQVR4nO3deVxU1f8/8NcFYUCWQZDVFFFJ3E3ccF8wXHLF3RLcMsUNcolvaVrqKFaau5WhWZZrbrmkWJjlimmZiru4gYICijAgnN8f/piPIyAM3uHi+Ho+HvehnDlzzrkzd2be8z7n3pGEEAJERERERmCm9ACIiIjIdDHQICIiIqNhoEFERERGw0CDiIiIjIaBBhERERkNAw0iIiIyGgYaREREZDQMNIiIiMhoGGgQERGR0bw0gYYkSZg+fbrB97t69SokScKqVatkH5Ncdu/ejfr168PKygqSJCE5OVnW9letWgVJknD16lVZ233ZGePYOHbsGJo1awYbGxtIkoSTJ0/K1nZp9/vvv0OSJPz+++9G6yM4OBiVK1c2WvvGoPR7kDFe/xEREfDx8UFOTo5sbb6o4n5GGEtJvB4KkpWVhYoVK2Lp0qUl3nd+DAo0cg9YSZJw8ODBPLcLIVCxYkVIkoS33npLtkGasqSkJPTt2xfW1tZYsmQJ1qxZAxsbG6WH9dLZuXOn4m8yWVlZ6NOnD+7du4f58+djzZo18PT0VHRMZBzTp0/XvRc+b2vTpk2+9y8Nx2txpaamYu7cuZgyZQrMzJ58hDx69AjTp083+ofqy/y4GeJF99PCwgJhYWGYNWsWMjIy5BtYcQkDREZGCgDCyspKjBo1Ks/tv/32mwAgVCqV6NKliyFNFwqA+Pjjjw2+35UrVwQAERkZKet45LJr1y4BQOzdu9dofTx+/Fikp6eLnJwco/WhtJCQEGHg4SxycnJEenq6ePz4sSxjOHv2rAAgvv76a1nae9lkZ2eL9PR0kZ2dbbQ+goKChKenp9HaL6pTp06JNWvW6LZly5YJAKJnz5565b/++mu+x1lxjtfikvv1P3/+fGFvby/S09N1ZXfv3i32e7Qhnve4paeni6ysLKP2b4jcz8PffvvN4PvKcXzcv39fWFpaipUrV75QO3IoU5zgpHPnztiwYQMWLlyIMmX+18TatWvh6+uLxMTEF4l9Xil37twBADg4OBitD3Nzc5ibmxut/ZfN48ePkZOTA0tLS1hZWcnWrjGey7S0NMUyXE8/TkVhZmYm6+NZmtWtWxd169bV/Z2YmIhRo0ahbt26ePvtt/PUV/Jxkfv1HxkZiW7dupW657q0jUdpDg4OePPNN7Fq1SoMHTpU0bEUa43GgAEDkJSUhL179+rKMjMzsXHjRgwcODDf+6SlpeH9999HxYoVoVKpUL16dXz22WcQz/x4rFarRWhoKJydnWFnZ4du3brhxo0b+bZ58+ZNDB06FK6urlCpVKhVqxa+/fbb4uwSACA5ORmhoaGoXLkyVCoVXnvtNQwePFgvcLpz5w6GDRsGV1dXWFlZoV69eli9erVeO7lzsp999hm++uorVK1aFSqVCo0aNcKxY8d09dq0aYOgoCAAQKNGjSBJEoKDgwEAlStX1v3/aW3atMmTjl20aBFq1aqFsmXLoly5cmjYsCHWrl2ru72gOdqlS5eiVq1aUKlU8PDwQEhISJ71IW3atEHt2rVx5swZtG3bFmXLlkWFChUQERFRpMdUkiSMGTMGGzZsQM2aNWFtbQ0/Pz/8+++/AIAVK1agWrVqsLKyQps2bfKM8Y8//kCfPn1QqVIlqFQqVKxYEaGhoUhPT9fVCQ4OxpIlS3T95W6A/nOxYMEC3XNx5syZPHPnd+7cgbOzM9q0aaN3XF68eBE2Njbo169fgfsZHByM1q1bAwD69OmTJ22+f/9+tGzZEjY2NnBwcED37t1x9uxZvTZy0/FnzpzBwIEDUa5cObRo0aLAPrOysjBjxgx4e3vDysoKTk5OaNGihd7rMr/jJXe8T691KOhx+vvvv1GmTBnMmDEjTxuxsbGQJAmLFy8GkHdOesyYMbC1tcWjR4/y3HfAgAFwc3NDdnY2AGDr1q3o0qULPDw8oFKpULVqVXz66ae624ujJI7vonj2OHve8QoAn332GZo1awYnJydYW1vD19cXGzduzNNu7mtry5YtqF27tu49cPfu3Xr1Cnr979q1C61bt4adnR3s7e3RqFEjvfeN/Fy5cgX//PMP/P399fbP2dkZADBjxgzd/jyd+j937hx69+4NR0dHWFlZoWHDhti2bZte24Udz4U9bs/2mft6unjxIoKDg+Hg4AC1Wo0hQ4bkOSbT09Mxbtw4lC9fXve5c/PmzSKv+7hx4wZ69OgBGxsbuLi4IDQ0FFqtNk+9F30/A4p+fABAhw4dcPDgQdy7d6/QfTCmYmU0KleuDD8/P/z444/o1KkTgCcHbUpKCvr374+FCxfq1RdCoFu3bvjtt98wbNgw1K9fH3v27MGkSZNw8+ZNzJ8/X1d3+PDh+P777zFw4EA0a9YM+/fvR5cuXfKMISEhAU2bNtW92JydnbFr1y4MGzYMqampmDBhgkH79PDhQ7Rs2RJnz57F0KFD0aBBAyQmJmLbtm24ceMGypcvj/T0dLRp0wYXL17EmDFj4OXlhQ0bNiA4OBjJyckYP368Xptr167FgwcPMHLkSEiShIiICPTq1QuXL1+GhYUFPvzwQ1SvXh1fffUVPvnkE3h5eaFq1aoGjfvrr7/GuHHj0Lt3b4wfPx4ZGRn4559/cOTIkQKDPuDJi3DGjBnw9/fHqFGjEBsbi2XLluHYsWP4888/YWFhoat7//59dOzYEb169ULfvn2xceNGTJkyBXXq1NE9/8/zxx9/YNu2bQgJCQEAaDQavPXWW5g8eTKWLl2K0aNH4/79+4iIiMDQoUOxf/9+3X03bNiAR48eYdSoUXBycsLRo0exaNEi3LhxAxs2bAAAjBw5Erdu3cLevXuxZs2afMcQGRmJjIwMvPvuu1CpVHB0dMyzkM3FxQXLli1Dnz59sGjRIowbNw45OTkIDg6GnZ3dcxdWjRw5EhUqVMDs2bMxbtw4NGrUCK6urgCAffv2oVOnTqhSpQqmT5+O9PR0LFq0CM2bN8eJEyfyLG7s06cPvL29MXv27DyB+NOmT58OjUaD4cOHo3HjxkhNTcXx48dx4sQJdOjQoeAn5DmefZzc3d3RunVrrF+/Hh9//LFe3XXr1sHc3Bx9+vTJt61+/fphyZIl+OWXX/TqPHr0CNu3b0dwcLDum/aqVatga2uLsLAw2NraYv/+/Zg2bRpSU1Mxb948g/ejJI9vQxV2vH755Zfo1q0bBg0ahMzMTPz000/o06cPduzYkee98ODBg9i8eTNGjx4NOzs7LFy4EIGBgYiLi4OTk1OBY8j9llurVi2Eh4fDwcEBf//9N3bv3v3c942//voLANCgQQNdmbOzM5YtW4ZRo0ahZ8+e6NWrFwDoMj7//fcfmjdvjgoVKuCDDz6AjY0N1q9fjx49emDTpk3o2bMngMKP56K8zvPTt29feHl5QaPR4MSJE/jmm2/g4uKCuXPn6uoEBwdj/fr1eOedd9C0aVNER0fn+7mTn/T0dLRv3x5xcXEYN24cPDw8sGbNGr33sVxyvJ8Zcnz4+vpCCIG//vpL2XWThsyz5K7ROHbsmFi8eLGws7MTjx49EkII0adPH9G2bVshhBCenp56azS2bNkiAIiZM2fqtde7d28hSZK4ePGiEEKIkydPCgBi9OjRevUGDhyYZ/5v2LBhwt3dXSQmJurV7d+/v1Cr1bpxFXWNxrRp0wQAsXnz5jy35c5tLliwQAAQ33//ve62zMxM4efnJ2xtbUVqaqpen05OTuLevXu6ulu3bhUAxPbt23VlTz+mT/P09BRBQUF5xtK6dWvRunVr3d/du3cXtWrVeu6+5fZx5coVIYQQd+7cEZaWluLNN9/Um09fvHixACC+/fZbvf4AiO+++05XptVqhZubmwgMDHxuv0II3Zqd3L6FEGLFihUCgHBzc9M9ZkIIER4erjdOIYTueXyaRqMRkiSJa9eu6coKmtPMfS7s7e3FnTt38r3t2WNjwIABomzZsuL8+fNi3rx5AoDYsmVLofuaOye7YcMGvfL69esLFxcXkZSUpCs7deqUMDMzE4MHD9aVffzxxwKAGDBgQKF9CSFEvXr1Cl0L9ezxkuvZtQ7Pe5xyn69///1Xr7xmzZqiXbt2ur+fnZPOyckRFSpUyHOcrF+/XgAQBw4c0JXl9zyPHDlSlC1bVmRkZBQ47vyU5PGd63lrFPI7zp43B//sY5GZmSlq166t91gL8eS1ZWlpqXv/FOLJcQVALFq0SFf27Os/OTlZ2NnZiSZNmuitsxBCFLqO46OPPhIAxIMHD/TKn7f/7du3F3Xq1NF7HnNyckSzZs2Et7e3rqwox/PzHrdn+899PQ0dOlSvXs+ePYWTk5Pu75iYGAFATJgwQa9ecHBwkdad5H4urF+/XleWlpYmqlWrlmeNxou+n+XXRkHHhxBC3Lp1SwAQc+fOfe4+GFuxT2/t27cv0tPTsWPHDjx48AA7duwoMBLeuXMnzM3NMW7cOL3y999/H0II7Nq1S1cPQJ56z2YnhBDYtGkTunbtCiEEEhMTdVtAQABSUlJw4sQJg/Zn06ZNqFevni66flpu2mrnzp1wc3PDgAEDdLdZWFhg3LhxePjwIaKjo/Xu169fP5QrV073d8uWLQEAly9fNmhsz+Pg4IAbN27oTckUZt++fcjMzMSECRN0q8YBYMSIEbC3t8cvv/yiV9/W1lZv3tnS0hKNGzcu8n60b99e71t7kyZNAACBgYGws7PLU/50u9bW1rr/p6WlITExEc2aNYMQAn///XeR+s/tKze9W5jFixdDrVajd+/emDp1Kt555x107969yH097fbt2zh58iSCg4Ph6OioK69bty46dOigO+af9t577xWpbQcHB/z333+4cOFCscaWn/wep169eqFMmTJYt26druz06dM4c+bMc6eTJElCnz59sHPnTjx8+FBXvm7dOlSoUEFvWujp5/nBgwdITExEy5Yt8ejRI5w7d86gfSjp41tuTz8W9+/fR0pKClq2bJnve5q/v79eFrRu3bqwt7d/7tj37t2LBw8e4IMPPsizruHpFH1+kpKSUKZMGdja2hZpX+7du4f9+/ejb9++uuc1MTERSUlJCAgIwIULF3Dz5k0Axjmegbyvp5YtWyIpKQmpqakAoJtqGj16tF69sWPHFqn9nTt3wt3dHb1799aVlS1bFu+++26eunK8nxlyfOR+/ii9brLYgYazszP8/f2xdu1abN68GdnZ2XoP9NOuXbsGDw8PvQ8VAKhRo4bu9tx/zczM8kwfVK9eXe/vu3fvIjk5GV999RWcnZ31tiFDhgD438K8orp06RJq16793DrXrl2Dt7e33ptXfvuRq1KlSnp/5z7p9+/fN2hszzNlyhTY2tqicePG8Pb2RkhICP7888/n3id3nM8+rpaWlqhSpUqe/XjttdfyvAGVK1euyPvx7OOgVqsBABUrVsy3/Ol24+LidB/Stra2cHZ21q2FSElJKVL/AODl5VXkuo6Ojli4cCH++ecfqNXqPFOBhijosQaeHDeJiYlIS0sr1lg/+eQTJCcn4/XXX0edOnUwadIk/PPPP8Uea0F9ly9fHu3bt8f69et1ZevWrUOZMmV0afKC9OvXD+np6br5+IcPH2Lnzp26dSy5/vvvP/Ts2RNqtRr29vZwdnbWffgb8jwDJX98y23Hjh1o2rQprKys4OjoqJuayO9xePa1BRQ+9kuXLgFAoe93crh48SKEEJg6dWqe9+rcqbjc92pjHM9A4e/DuZ87zx771apVK1L7165dQ7Vq1fIcQ/m95uV4PzPk+BD/f+q1sADS2Iq1RiPXwIEDMWLECMTHx6NTp05GPXPiablz62+//bZuMeWznl4RrpSCVnqL58y75yrowMjOztZrt0aNGoiNjcWOHTuwe/dubNq0CUuXLsW0adPyXcBXHC+yH8+7f2HtZmdno0OHDrh37x6mTJkCHx8f2NjY4ObNmwgODjboYkFPfwsoij179gB48mZ048aNEju2gaKPtVWrVrh06RK2bt2KX3/9Fd988w3mz5+P5cuXY/jw4QCeHEf5PU8FLbIsqO/+/ftjyJAhOHnyJOrXr4/169ejffv2KF++/HPH2LRpU1SuXBnr16/HwIEDsX37dqSnp+tlQpKTk9G6dWvY29vjk08+QdWqVWFlZYUTJ05gypQpRr8o1Ise33L6448/0K1bN7Rq1QpLly6Fu7s7LCwsEBkZme9CzZIeu5OTEx4/fowHDx7k+eKYn9znbuLEiQgICMi3Tu4HelGO5+IoLc+vHO9nhh4fucFUYa9TY3uhQKNnz54YOXIkDh8+rJdWfZanpyf27duX5+DMTYnmXtTI09MTOTk5uHTpkl40GBsbq9de7hkp2dnZequfX0TVqlVx+vTp59bx9PTEP//8g5ycHL2sxrP7IYdy5crle4XQa9euoUqVKnpluWdE9OvXD5mZmejVqxdmzZqF8PDwfE/5yh1nbGysXluZmZm4cuWKbI/pi/r3339x/vx5rF69GoMHD9aVP31WRS45I/bdu3fjm2++weTJk/HDDz8gKCgIR44c0TuVu6iefqyfde7cOZQvX/6FTl91dHTEkCFDMGTIEDx8+BCtWrXC9OnTdW/M5cqVyzeN/uy3+sL06NEDI0eO1L3Oz58/j/Dw8CLdt2/fvvjyyy+RmpqKdevWoXLlymjatKnu9t9//x1JSUnYvHkzWrVqpSu/cuWKQWPM9TIc3wUdr5s2bYKVlRX27NkDlUqlK4+MjJSt79yM8enTp4v8rT2Xj48PgCfPzdNf5gran9zH38LCokiPe2HHszG+med+7ly5cgXe3t668osXLxb5/qdPn4YQQm98z77m5Xg/M/T4yH0N5WbdlfJClyC3tbXFsmXLMH36dHTt2rXAep07d0Z2drbuNLhc8+fPhyRJupXduf8+m6pesGCB3t/m5uYIDAzEpk2b8g0O7t69a/C+BAYG4tSpU/j555/z3JYb+Xbu3Bnx8fF6QdXjx4+xaNEi2Nra6lJgcqhatSoOHz6MzMxMXdmOHTtw/fp1vXpJSUl6f1taWqJmzZoQQiArKyvftv39/WFpaYmFCxfqRfUrV65ESkpKkVdbG1vuN5GnxyiEwJdffpmnbu6H9Ytevj05OVm36n327Nn45ptvcOLECcyePbtY7bm7u6N+/fpYvXq13thOnz6NX3/9FZ07dy72WJ997m1tbVGtWjW90+qqVq2Kc+fO6b0mTp06Vej02rMcHBwQEBCA9evX46effoKlpSV69OhRpPv269cPWq0Wq1evxu7du9G3b1+92/N7njMzM4t9+eSX4fgu6Hg1NzeHJEl6GaerV69iy5YtsvX95ptvws7ODhqNJs9VIwv7lu/n5wcAOH78uF552bJlAeTdHxcXF7Rp0wYrVqzA7du387T39HFZlONZrtf503IzLc8eb4sWLSrS/Tt37oxbt27pnWL66NEjfPXVV3r15Hg/M/T4iImJgSRJuudNKS+U0QBQ4NTF07p27Yq2bdviww8/xNWrV1GvXj38+uuv2Lp1KyZMmKCLsOvXr48BAwZg6dKlSElJQbNmzRAVFZVvZDlnzhz89ttvaNKkCUaMGIGaNWvi3r17OHHiBPbt22fwecOTJk3Cxo0b0adPHwwdOhS+vr64d+8etm3bhuXLl6NevXp49913sWLFCgQHByMmJgaVK1fGxo0b8eeff2LBggVFSiUW1fDhw7Fx40Z07NgRffv2xaVLl/D999/nWb/y5ptvws3NDc2bN4erqyvOnj2LxYsXo0uXLgWOx9nZGeHh4ZgxYwY6duyIbt26ITY2FkuXLkWjRo3yveCQEnx8fFC1alVMnDgRN2/ehL29PTZt2pTv/LOvry+AJwuJAwICYG5ujv79+xvc5/jx45GUlIR9+/bB3NwcHTt2xPDhwzFz5kx0794d9erVM7jNefPmoVOnTvDz88OwYcN0p7eq1eoXusxwzZo10aZNG/j6+sLR0RHHjx/Hxo0bMWbMGF2doUOH4osvvkBAQACGDRuGO3fuYPny5ahVq5ZuMVxR9evXD2+//TaWLl2KgICAIk8nNWjQANWqVcOHH34IrVabZwFps2bNUK5cOQQFBWHcuHGQJAlr1qwpdmr7ZTi+Czpeu3Tpgi+++AIdO3bEwIEDcefOHSxZsgTVqlWTZb0CANjb22P+/PkYPnw4GjVqpLtmy6lTp/Do0aM81wV6WpUqVVC7dm3s27dP7yJQ1tbWqFmzJtatW4fXX38djo6OqF27NmrXro0lS5agRYsWqFOnDkaMGIEqVaogISEBhw4dwo0bN3Dq1CkARTue5XqdP83X1xeBgYFYsGABkpKSdKe3nj9/HkDhWZQRI0Zg8eLFGDx4MGJiYuDu7o41a9bogq9ccryfGXp87N27F82bN3/uqc4lwpBTVAo6FfNZz57eKoQQDx48EKGhocLDw0NYWFgIb29vMW/evDynU6Wnp4tx48YJJycnYWNjI7p27SquX7+e72lGCQkJIiQkRFSsWFFYWFgINzc30b59e/HVV1/p6hhyCfKkpCQxZswYUaFCBWFpaSlee+01ERQUpHcKbUJCghgyZIgoX768sLS0FHXq1MnTdm6f8+bNy9PHs/vxvMf0888/FxUqVBAqlUo0b95cHD9+PM/piitWrBCtWrUSTk5OQqVSiapVq4pJkyaJlJSUPH08fdqoEE9O9/Px8REWFhbC1dVVjBo1Sty/f1+vTuvWrfM9fbaol4IGIEJCQvTKCnp88js99MyZM8Lf31/Y2tqK8uXLixEjRuhO4Xv6cX/8+LEYO3ascHZ2FpIk6U4Ne95z8eyxkXv68eeff65XLzU1VXh6eop69eqJzMzMAve1oNNbhRBi3759onnz5sLa2lrY29uLrl27ijNnzujVyT0d7+7duwX28bSZM2eKxo0bCwcHB2FtbS18fHzErFmz8ozx+++/F1WqVBGWlpaifv36Ys+ePQWe3prf4/T042BtbZ3nFO9n9z+/Sy5/+OGHAoCoVq1avm3/+eefomnTpsLa2lp4eHiIyZMniz179uRpz5BLkJfE8Z3L0NNbCzpehRBi5cqVwtvbW6hUKuHj4yMiIyN1x8bT8nttCZH31PiCXv/btm0TzZo10x2TjRs3Fj/++GOh+/rFF18IW1vbPKdZ/vXXX8LX11dYWlrmeSwuXbokBg8eLNzc3ISFhYWoUKGCeOutt8TGjRt1dYpyPD/vcXu2z4JeT/k9HmlpaSIkJEQ4OjoKW1tb0aNHDxEbGysAiDlz5hT6mFy7dk1069ZNlC1bVpQvX16MHz9e7N69O8/x+6LvZ0IU/fhITk4WlpaW4ptvvil0/MYmCaHAiiciInoppaSkoEqVKoiIiMCwYcOUHo7RnDx5Em+88Qa+//57DBo0SOnhGGzBggWIiIjApUuXDF4ML7eX5mfiiYhIeWq1GpMnT8a8efNK1c/Ev4inLwGea8GCBTAzM9NboPyyyMrKwhdffIGPPvpI8SADAJjRICKiV9qMGTMQExODtm3bokyZMti1axd27dqlW5dHL4aBBhERvdL27t2LGTNm4MyZM3j48CEqVaqEd955Bx9++GGxTmsnfQw0iIiIyGi4RoOIiIiMhoEGERERGQ0DDSIiIjKaV3KVi3WlAYVXInrFJF0eXXgloldM2TItjd6HnJ9J6XE/ytaWXJjRICIiIqN5JTMaREREpYUkmfZ3fgYaRERECpJMfHKBgQYREZGCTD2jYdp7R0RERIpiRoOIiEhBpp7RYKBBRESkIEmSlB6CUZl2GEVERESKYkaDiIhIUab9nZ+BBhERkYJMfY2Gae8dERERKYoZDSIiIgWZekaDgQYREZGCTP3KoKa9d0RERKQoZjSIiIgUxKkTIiIiMhoGGkRERGQ0ph5omPbeERERkaKY0SAiIlKQBNP+rRMGGkRERAri1AkRERFRMTGjQUREpCBmNIiIiMhoJMlMts0QDx48wIQJE+Dp6Qlra2s0a9YMx44d090uhMC0adPg7u4Oa2tr+Pv748KFCwbvHwMNIiKiV9Dw4cOxd+9erFmzBv/++y/efPNN+Pv74+bNmwCAiIgILFy4EMuXL8eRI0dgY2ODgIAAZGRkGNSPJIQQxtiB0sy60gClh0BU6iRdHq30EIhKnbJlWhq9D7ea4bK1FX9GU6R66enpsLOzw9atW9GlSxddua+vLzp16oRPP/0UHh4eeP/99zFx4kQAQEpKClxdXbFq1Sr079+/yGNiRoOIiEhBSkydPH78GNnZ2bCystIrt7a2xsGDB3HlyhXEx8fD399fd5tarUaTJk1w6NAhg/aPgQYREZGJ0Gq1SE1N1du0Wm2eenZ2dvDz88Onn36KW7duITs7G99//z0OHTqE27dvIz4+HgDg6uqqdz9XV1fdbUXFQIOIiEhBcmY0NBoN1Gq13qbR5D+dsmbNGgghUKFCBahUKixcuBADBgyAmZm8oQEDDSIiIgVJMJNtCw8PR0pKit4WHp7/GpCqVasiOjoaDx8+xPXr13H06FFkZWWhSpUqcHNzAwAkJCTo3SchIUF3W1Ex0CAiIlKQnBkNlUoFe3t7vU2lUj23fxsbG7i7u+P+/fvYs2cPunfvDi8vL7i5uSEqKkpXLzU1FUeOHIGfn59B+8cLdhEREb2C9uzZAyEEqlevjosXL2LSpEnw8fHBkCFDIEkSJkyYgJkzZ8Lb2xteXl6YOnUqPDw80KNHD4P6YaBBRESkIElS5kfVcqdVbty4AUdHRwQGBmLWrFmwsLAAAEyePBlpaWl49913kZycjBYtWmD37t15zlQpDK+jQUQAeB0NovyUxHU0KtWbKVtbcac+kq0tuXCNBhERERkNp06IiIgUJJn4d34GGkRERArir7cSERERFRMzGkRERAoy9YwGAw0iIiIFmfoaDdPeOyIiIlIUMxpERERK4tQJERERGQvXaBAREZHRKHUJ8pJi2mEUERERKYoZDSIiIgWZ+lknDDSIiIgUZOprNEx774iIiEhRzGgQEREpycQXgzLQICIiUpKJzy2Y+O4RERGRkpjRICIiUhKnToiIiMhoTDzQ4NQJERERGQ0zGkREREoy8a/8DDSIiIgUJEx86oSBBhERkZJMO84w9YQNERERKYkZDSIiIiWZmXZKg4EGERGRkkx8jQanToiIiMhomNEgIiJSkmknNBhoEBERKcrE12hw6oSIiIiMhhkNIiIiJZn4YlAGGkREREoy7TiDUydERERkPMxoEBERKcnEF4My0CAiIlKSaccZnDohIiJSkpAk2baiys7OxtSpU+Hl5QVra2tUrVoVn376KYQQ/xuXEJg2bRrc3d1hbW0Nf39/XLhwweD9Y6BBRET0ipk7dy6WLVuGxYsX4+zZs5g7dy4iIiKwaNEiXZ2IiAgsXLgQy5cvx5EjR2BjY4OAgABkZGQY1BenToiIiJSkwBqNv/76C927d0eXLl0AAJUrV8aPP/6Io0ePAniSzViwYAE++ugjdO/eHQDw3XffwdXVFVu2bEH//v2L3BczGkREREqS5Nu0Wi1SU1P1Nq1Wm6fLZs2aISoqCufPnwcAnDp1CgcPHkSnTp0AAFeuXEF8fDz8/f1191Gr1WjSpAkOHTpk0O4x0CAiIjIRGo0GarVab9NoNHnqffDBB+jfvz98fHxgYWGBN954AxMmTMCgQYMAAPHx8QAAV1dXvfu5urrqbisqTp0QEREpScYrg4aHhyMsLEyvTKVS5am3fv16/PDDD1i7di1q1aqFkydPYsKECfDw8EBQUJBs4wEYaBARESlLxjUaKpUq38DiWZMmTdJlNQCgTp06uHbtGjQaDYKCguDm5gYASEhIgLu7u+5+CQkJqF+/vkFj4tQJERHRK+bRo0cwM9MPAczNzZGTkwMA8PLygpubG6KionS3p6am4siRI/Dz8zOoL2Y0iIiIlKTABbu6du2KWbNmoVKlSqhVqxb+/vtvfPHFFxg6dOiTIUkSJkyYgJkzZ8Lb2xteXl6YOnUqPDw80KNHD4P6YqBBRESkJAV+vXXRokWYOnUqRo8ejTt37sDDwwMjR47EtGnTdHUmT56MtLQ0vPvuu0hOTkaLFi2we/duWFlZGdSXJJ6+DNgrwrrSAKWHQFTqJF0erfQQiEqdsmVaGr2Par3WyNbWxc3vyNaWXJjRICIiUpICGY2SxECDiIhISSZ+WgYDDSIiIiWZeEbDxOMoIiIiUhIzGkREREoy7YQGAw0iIiIlCQV+vbUkceqEiIiIjIYZDTI6WxsrfDyxL7oFNIRzeTVOnb6KidNXI+afy7o61at5YGb4QLRsUgNlypjh3IWbGDByPq7fSlJw5ETGsfLrndi/9wSuXrkNlZUl6tWvivFhvVHZy01XZ9P6aOzaeQTnzsQhLS0DBw4thJ19WQVHTUbDxaBEL2ZZxLto17IOhk5YioYdJmPfH//gl7UfwsO1HADAy9MFUZum4/ylWwjo9ykaBUyBZuHPyNBmKTxyIuM4cSwW/Qa0xXc//h+WfR2Gx4+zMWrEF0h/pNXVycjIRLPmtTF0RGcFR0olQpJxK4WY0SCjslJZoEenxugz/HP8efQcAGDW/E3o7N8AI97pgBmfrceMSf2w57eT+HD2Wt39rly7o9SQiYxuyVehen/PmDUU7VuG4syZa/Bt+DoAYNDgDgCA4///dUP0sirVgUZiYiK+/fZbHDp0CPHx8QAANzc3NGvWDMHBwXB2dlZ4hFSYMmXMUaaMOTK0mXrlGRmZaNaoOiRJQsd2b+CL5duxbc0HqFerMq5dv4t5S7Zi+6/HFRo1Ucl6+OARAECttlF4JKQILgZVxrFjx/D6669j4cKFUKvVaNWqFVq1agW1Wo2FCxfCx8cHx4/zg6i0e5iWgcPHzyN8XC+4u5aDmZmE/j1boEmD1+Hm4gCX8vaws7XGxNHdsPf3U+j6tgbb9hzDT1+FokWTGkoPn8jocnJy8Nncdaj/RjVU866g9HBICZIk31YKldqMxtixY9GnTx8sX74c0jMPnhAC7733HsaOHYtDhw49tx2tVgutVqtXJkQ2JMlc9jFT/oaGLsGKee/h8rGlePw4GydPX8H6rX/hjTpeMDN7Euvu+DUGi1buAgD8c+Yamvi+jhFv++PgkbNKDp3I6DQzf8DFCzcRuWaK0kMhMopSm9E4deoUQkND8wQZACBJEkJDQ3Hy5MlC29FoNFCr1Xrb49QzRhgxFeTKtTt4s+8ncKoeDO+mY9Cy21RYWJjjStwdJN5LRVbWY5y9cFPvPrEXb6JiBSeFRkxUMubM/AF/RP+DryMnwtXNUenhkFJMfDFoqQ003NzccPTo0QJvP3r0KFxdXQttJzw8HCkpKXpbGfuacg6ViuhRuhbxd5LhoLaBf6u62LH3OLKyshFz6jJer+quV9fbyx1xNxIVGimRcQkhMGfmD9gf9TdWfDsRFV7jerNXmpkk31YKldqpk4kTJ+Ldd99FTEwM2rdvrwsqEhISEBUVha+//hqfffZZoe2oVCqoVCq9Mk6blCz/VnUhSRLOX76FqpXdMPv/BuL8pVv4bn00AGD+iu1Ys2Q8Dh45h+i//sObbeqhs38DBPT7VOGRExmH5tMfsGvnEcxfNAY2Za2QeDcFAGBrZw0rK0sAQOLdFCQlpiAu7skZWBcu3IBNWSu4uTtC7WCr2NjJCEppgCAXSQghlB5EQdatW4f58+cjJiYG2dnZAABzc3P4+voiLCwMffv2LVa71pUGyDlMKkTgW03xyZT+qODmiHspD7F151F8PG8dUh+k6+oM7tsGk0K6oYK7E85fuoWZX2zEjr0xCo761ZN0ebTSQ3hlvFFreL7lM2YOQbeezQEAy5dsxYql259bh4yvbJmWRu+j6rANsrV1aWUf2dqSS6kONHJlZWUhMfFJGr18+fKwsLB4ofYYaBDlxUCDKK+SCDSqDJcv0Lj8TekLNErt1MnTLCws4O7uXnhFIiKil42JT52U2sWgRERE9PJ7KTIaREREJquUXmhLLgw0iIiIlMSpEyIiIqLiYUaDiIhISSb+lZ+BBhERkZJMfI2GicdRREREpCRmNIiIiJRk4otBGWgQEREpSJj41AkDDSIiIiWZ+CIGE989IiIiUhIzGkREREriGg0iIiIyGhNfo8GpEyIiIjIaZjSIiIiUZOJTJ8xoEBERKUmScTNA5cqVIUlSni0kJAQAkJGRgZCQEDg5OcHW1haBgYFISEgwePcYaBAREb2Cjh07htu3b+u2vXv3AgD69OkDAAgNDcX27duxYcMGREdH49atW+jVq5fB/XDqhIiISEFCoakTZ2dnvb/nzJmDqlWronXr1khJScHKlSuxdu1atGvXDgAQGRmJGjVq4PDhw2jatGmR+2FGg4iISElmknxbMWVmZuL777/H0KFDIUkSYmJikJWVBX9/f10dHx8fVKpUCYcOHTKobWY0iIiITIRWq4VWq9UrU6lUUKlUz73fli1bkJycjODgYABAfHw8LC0t4eDgoFfP1dUV8fHxBo2JGQ0iIiIlSZJsm0ajgVqt1ts0Gk2hQ1i5ciU6deoEDw8P2XePGQ0iIiIlyfiVPzw8HGFhYXplhWUzrl27hn379mHz5s26Mjc3N2RmZiI5OVkvq5GQkAA3NzeDxsSMBhERkZJkzGioVCrY29vrbYUFGpGRkXBxcUGXLl10Zb6+vrCwsEBUVJSuLDY2FnFxcfDz8zNo95jRICIiekXl5OQgMjISQUFBKFPmfyGBWq3GsGHDEBYWBkdHR9jb22Ps2LHw8/Mz6IwTgIEGERGRshS8Mui+ffsQFxeHoUOH5rlt/vz5MDMzQ2BgILRaLQICArB06VKD+5CEEEKOwb5MrCsNUHoIRKVO0uXRSg+BqNQpW6al0fuo/OmvsrV1deqbsrUlF67RICIiIqPh1AkREZGChIn/TDwDDSIiIiWZ+NyCie8eERERKYkZDSIiIiVx6oSIiIiMRsHTW0sCp06IiIjIaJjRICIiUpKJZzQYaBARESnJtOMMBhpERERKEiae0eAaDSIiIjIaZjSIiIiUxNNbiYiIyGg4dUJERERUPMxoEBERKcm0ExoMNIiIiJRkZuJzCya+e0RERKQkZjSIiIgUZOInnTDQICIiUhIDDSIiIjIaycQjDa7RICIiIqNhRoOIiEhBJp7QYKBBRESkJFMPNDh1QkREREbDjAYREZGCJBP/ys9Ag4iISEGcOiEiIiIqJmY0iIiIFGTivxLPQIOIiEhJnDohIiIiKiZmNIiIiBRk6hkNBhpEREQKMvXfOmGgQUREpCBTv46Gie8eERERKYkZDSIiIgWZ+MwJMxpERERKkiT5NkPcvHkTb7/9NpycnGBtbY06derg+PHjutuFEJg2bRrc3d1hbW0Nf39/XLhwweD9Y6BBRET0irl//z6aN28OCwsL7Nq1C2fOnMHnn3+OcuXK6epERERg4cKFWL58OY4cOQIbGxsEBAQgIyPDoL44dUJERKQgJaZO5s6di4oVKyIyMlJX5uXlpfu/EAILFizARx99hO7duwMAvvvuO7i6umLLli3o379/kftiRoOIiEhBZpJ8m1arRWpqqt6m1Wrz9Llt2zY0bNgQffr0gYuLC9544w18/fXXutuvXLmC+Ph4+Pv768rUajWaNGmCQ4cOGbZ/xX9oiIiIqDTRaDRQq9V6m0ajyVPv8uXLWLZsGby9vbFnzx6MGjUK48aNw+rVqwEA8fHxAABXV1e9+7m6uupuKypOnRARESlIzqmT8PBwhIWF6ZWpVKo89XJyctCwYUPMnj0bAPDGG2/g9OnTWL58OYKCguQbEGQINLZt21bkut26dXvR7oiIiEyKnIGGSqXKN7B4lru7O2rWrKlXVqNGDWzatAkA4ObmBgBISEiAu7u7rk5CQgLq169v0JheONDo0aNHkepJkoTs7OwX7Y6IiIheUPPmzREbG6tXdv78eXh6egJ4sjDUzc0NUVFRusAiNTUVR44cwahRowzq64UDjZycnBdtgoiI6JUlmZX8aSehoaFo1qwZZs+ejb59++Lo0aP46quv8NVXXz0ZkyRhwoQJmDlzJry9veHl5YWpU6fCw8OjyAmGXFyjQUREpCAlTm9t1KgRfv75Z4SHh+OTTz6Bl5cXFixYgEGDBunqTJ48GWlpaXj33XeRnJyMFi1aYPfu3bCysjKoL0kIIeQcfFpaGqKjoxEXF4fMzEy928aNGydnV8VmXWmA0kMgKnWSLo9WeghEpU7ZMi2N3keTjQdla+tI7xaytSUXWTMaf//9Nzp37oxHjx4hLS0Njo6OSExMRNmyZeHi4lJqAg0iIiIqGbJeRyM0NBRdu3bF/fv3YW1tjcOHD+PatWvw9fXFZ599JmdXREREJkGp3zopKbIGGidPnsT7778PMzMzmJubQ6vVomLFioiIiMD//d//ydkVERGRSZDzyqClkayBhoWFBczMnjTp4uKCuLg4AE8uW3r9+nU5uyIiIqKXgKxrNN544w0cO3YM3t7eaN26NaZNm4bExESsWbMGtWvXlrMrIiIik1BapzzkImtGY/bs2boriM2aNQvlypXDqFGjcPfuXd25uURERPQ/kpl8W2kka0ajYcOGuv+7uLhg9+7dcjZPRERELxlesIuIiEhBpj51Imug4eXlBek5j9jly5fl7I6IiOil97zPTVMga6AxYcIEvb+zsrLw999/Y/fu3Zg0aZKcXREREdFLQNZAY/z48fmWL1myBMePH5ezKyIiIpNg4gkNec86KUinTp10v3FPRERE/2PqVwYtkcWgGzduhKOjY0l0RURE9FIprQGCXGS/YNfTi1qEEIiPj8fdu3exdOlSObsiIiKil4CsgUb37t31Ag0zMzM4OzujTZs28PHxkbOrF5IeN0PpIRCVOpOP3lB6CESlTkRj4/dRWn+jRC6yBhrTp0+XszkiIiKTZ+qBhqyLQc3NzXHnzp085UlJSTA3N5ezKyIiInoJyJrREELkW67VamFpaSlnV0RERCbBTMr/s9NUyBJoLFy4EMCTq5t98803sLW11d2WnZ2NAwcOlKo1GkRERKWFqU+dyBJozJ8/H8CTjMby5cv1pkksLS1RuXJlLF++XI6uiIiI6CUiS6Bx5coVAEDbtm2xefNmlCtXTo5miYiITF4p/XV32ci6RuO3336TszkiIiKTZ+prNGQNpAIDAzF37tw85REREejTp4+cXREREdFLQNZA48CBA+jcuXOe8k6dOuHAgQNydkVERGQSzCT5ttJI1qmThw8f5nsaq4WFBVJTU+XsioiIyCSY+hoNWfevTp06WLduXZ7yn376CTVr1pSzKyIiIpPAjIYBpk6dil69euHSpUto164dACAqKgpr167Fxo0b5eyKiIiIXgKyBhpdu3bFli1bMHv2bGzcuBHW1taoV68e9u/fz5+JJyIiyodk4medyBpoAECXLl3QpUsXAEBqaip+/PFHTJw4ETExMcjOzpa7OyIiopdaaZ3ykItR1qAcOHAAQUFB8PDwwOeff4527drh8OHDxuiKiIiISjHZMhrx8fFYtWoVVq5cidTUVPTt2xdarRZbtmzhQlAiIqIC8KyTIujatSuqV6+Of/75BwsWLMCtW7ewaNEiOZomIiIyaWaSkG0rjWTJaOzatQvjxo3DqFGj4O3tLUeTREREZAJkyWgcPHgQDx48gK+vL5o0aYLFixcjMTFRjqaJiIhMmqlfR0OWQKNp06b4+uuvcfv2bYwcORI//fQTPDw8kJOTg7179+LBgwdydENERGRyzGTcSiNZx2VjY4OhQ4fi4MGD+Pfff/H+++9jzpw5cHFxQbdu3eTsioiIiIpp+vTpkCRJb/Px8dHdnpGRgZCQEDg5OcHW1haBgYFISEgoVl9GC4CqV6+OiIgI3LhxAz/++KOxuiEiInqpKTV1UqtWLdy+fVu3HTx4UHdbaGgotm/fjg0bNiA6Ohq3bt1Cr169irV/sl+w61nm5ubo0aMHevToYeyuiIiIXjpKnS1SpkwZuLm55SlPSUnBypUrsXbtWt3PiURGRqJGjRo4fPgwmjZtalA/pXVKh4iI6JUgZ0ZDq9UiNTVVb9Nqtfn2e+HCBXh4eKBKlSoYNGgQ4uLiAAAxMTHIysqCv7+/rq6Pjw8qVaqEQ4cOGb5/xXtYiIiIqLTRaDRQq9V6m0ajyVOvSZMmWLVqFXbv3o1ly5bhypUraNmyJR48eID4+HhYWlrCwcFB7z6urq6Ij483eExGnzohIiKigsn5jT88PBxhYWF6ZSqVKk+9Tp066f5ft25dNGnSBJ6enli/fj2sra1lHBEDDSIiIkXJuUZDpVLlG1gUxsHBAa+//jouXryIDh06IDMzE8nJyXpZjYSEhHzXdBSGUydERESvuIcPH+LSpUtwd3eHr68vLCwsEBUVpbs9NjYWcXFx8PPzM7htZjSIiIgUpMQVPSdOnIiuXbvC09MTt27dwscffwxzc3MMGDAAarUaw4YNQ1hYGBwdHWFvb4+xY8fCz8/P4DNOAAYaREREilIi0Lhx4wYGDBiApKQkODs7o0WLFjh8+DCcnZ0BAPPnz4eZmRkCAwOh1WoREBCApUuXFqsvBhpERESvmJ9++um5t1tZWWHJkiVYsmTJC/fFQIOIiEhBpr5YkoEGERGRgpS6MmhJMfVAioiIiBTEjAYREZGClFgMWpIYaBARESnI1KcWGGgQEREpyNQzGqYeSBEREZGCmNEgIiJSkGTiZ50w0CAiIlIQp06IiIiIiokZDSIiIgWZ+jd+BhpEREQK4pVBiYiIiIqJGQ0iIiIFmfpiUAYaRERECjL1QINTJ0RERGQ0zGgQEREpyFzpARgZAw0iIiIFmfpZJww0iIiIFMQ1GkRERETFxIwGERGRgkw9o8FAg4iISEHmJh5ocOqEiIiIjIYZDSIiIgVx6oSIiIiMxtRPb+XUCRERERkNMxpEREQK4tQJERERGY2pX4KcUydERERkNMxoEBERKYhTJ0RERGQ0pn7WCQMNIiIiBfHKoERERETFxIwGERGRgkx9jQYzGkRERAoyk+TbimvOnDmQJAkTJkzQlWVkZCAkJAROTk6wtbVFYGAgEhISDN+/4g+LiIiIXnbHjh3DihUrULduXb3y0NBQbN++HRs2bEB0dDRu3bqFXr16Gdw+Aw0iIiIFKZnRePjwIQYNGoSvv/4a5cqV05WnpKRg5cqV+OKLL9CuXTv4+voiMjISf/31Fw4fPmzY/hk+LCIiIpKLuSRk2wwVEhKCLl26wN/fX688JiYGWVlZeuU+Pj6oVKkSDh06ZFAfXAxKRERkIrRaLbRarV6ZSqWCSqXKU/enn37CiRMncOzYsTy3xcfHw9LSEg4ODnrlrq6uiI+PN2hMzGgQEREpyEzGTaPRQK1W620ajSZPn9evX8f48ePxww8/wMrKyqj7x4wGERGRguQ8vTU8PBxhYWF6ZfllM2JiYnDnzh00aNBAV5adnY0DBw5g8eLF2LNnDzIzM5GcnKyX1UhISICbm5tBY2KgQUREZCIKmiZ5Vvv27fHvv//qlQ0ZMgQ+Pj6YMmUKKlasCAsLC0RFRSEwMBAAEBsbi7i4OPj5+Rk0JgYaREREClLigl12dnaoXbu2XpmNjQ2cnJx05cOGDUNYWBgcHR1hb2+PsWPHws/PD02bNjWoLwYaRERECirO2SIlYf78+TAzM0NgYCC0Wi0CAgKwdOlSg9uRhBClcw+N6rzSAyAqdSYfvaH0EIhKnYjG7Yzex9Zru2Rrq7tnJ9nakgvPOiEiIiKj4dQJERGRgkz9R9UYaBARESnI1AMNTp0QERGR0TCjQUREpCBzE89oMNAgIiJSkFkpPb1VLpw6ISIiIqNhRoOIiEhBpv6Nn4EGERGRgnjWCREREVExMaNBRnfs2GmsXLkZp09fwt2797Bkyf/B3/9/v/73wQfz8fPP+/Xu06JFA6xcOaOkh0qkiPPb9+Ds+i2oEtAWdd7ui0d3k7A37KN86zYcMxwVmviW8AjJmHjWCdELevQoA9WreyEwsAPGjJmdb52WLRtAo5mg+9vS0qKERkekrPuXr+La/j9gX7GCrszaqRwCFs3Rq3ftt4O4sHMvXOvVKukhkpGZ+lknDDTI6Fq3bojWrRs+t46lpQWcncuV0IiISofHGRmIWRaJesMG4fzW//2wlmRmBisHtV7d2zEnUaGxL8pYWZX0MMnIuEaDqAQcPXoafn5vIyDgPXz88VLcv5+q9JCIjO6f1T/BtV5tuNSu8dx6yVeuIeXaDXi2blZCIyOSz0sbaFy/fh1Dhw4ttJ5Wq0VqaqreptVmlsAIqahatvTF3LmhWLVqJiZNCsKxY6cxYsR0ZGdnKz00IqO5cegYkq9eR82+PQqtey36L9h6uMHx9arGHxiVODNJvq00emkDjXv37mH16tWF1tNoNFCr1XqbRrOiBEZIRdWlSyu0b98E1atXhr+/H1asmIZ//72Ao0dPKz00IqNIT7qH099vgO+oITAvZD1SdmYmbhw6Bs/WzUtodFTSzGTcSqNSu0Zj27Ztz7398uXLRWonPDwcYWFhemUqVVyxx0XGV7GiG8qVs8e1a7fg51dP6eEQyS75Shy0qQ8QPVWjKxM5OUiKvYgre6PRNXIRJLMnHxu3jv6NbG0mKrZootRwiV5IqQ00evToAUmSIETBq3ElqfA8kUqlgkqleqbU8gVHR8YUH5+I5OQHcHZ2VHooREZRvpYP2s7WP33176/XwNbDFd5d3tQFGQBwLfpPuDWoC5W9XUkPk0pIET7KXmqlNdMCd3d3bN68GTk5OfluJ06cUHqIVERpaek4e/Yyzp59koW6cSMBZ89exq1bd5CWlo65c7/FyZPncONGAg4dOoXRo2fC09MdLVs2UHjkRMZhYW0F+4oV9DZzlSUsbW30TnN9mHAHSbEX4dmG0yamTJJxK41KbUbD19cXMTEx6N69e763F5btoNLj9OmLGDz4/3R/azQrAQA9e7bD9Omjcf78VWzZsh8PHqTBxcURzZu/gfHjB/FaGvTKi4v+C9aODoWelUJUmkmilH5a//HHH0hLS0PHjh3zvT0tLQ3Hjx9H69ati9H6+RcbHJEJmnz0htJDICp1Ihq3M3ofxxN/ka2thuW7yNaWXEptRqNly5bPvd3GxqaYQQYREVHpUWrXMMjE1PePiIiIFFRqMxpERESvAom/dUJERETGUlrPFpELAw0iIiIF8ToaRERERMXEjAYREZGCTDyhwUCDiIhISaX1V1flwqkTIiIiMhpmNIiIiBRk4gkNBhpERERK4lknRERERMXEjAYREZGCTDyhwUCDiIhISaYeaHDqhIiI6BWzbNky1K1bF/b29rC3t4efnx927dqluz0jIwMhISFwcnKCra0tAgMDkZCQUKy+GGgQEREpyEySbyuq1157DXPmzEFMTAyOHz+Odu3aoXv37vjvv/8AAKGhodi+fTs2bNiA6Oho3Lp1C7169SrW/klCCNP+2bh8nVd6AESlzuSjN5QeAlGpE9G4ndH7uJCyQ7a2vNVvFfu+jo6OmDdvHnr37g1nZ2esXbsWvXv3BgCcO3cONWrUwKFDh9C0aVOD2uUaDSIiIgXJ+TPxWq0WWq1Wr0ylUkGlUhV4n+zsbGzYsAFpaWnw8/NDTEwMsrKy4O/vr6vj4+ODSpUqFSvQ4NQJERGRidBoNFCr1XqbRqPJt+6///4LW1tbqFQqvPfee/j5559Rs2ZNxMfHw9LSEg4ODnr1XV1dER8fb/CYmNEgIiJSkJxnnYSHhyMsLEyvrKBsRvXq1XHy5EmkpKRg48aNCAoKQnR0tIyjeYKBBhERkYLkvDJoYdMkT7O0tES1atUAAL6+vjh27Bi+/PJL9OvXD5mZmUhOTtbLaiQkJMDNzc3gMXHqhIiIiJCTkwOtVgtfX19YWFggKipKd1tsbCzi4uLg5+dncLvMaBARESlIiW/84eHh6NSpEypVqoQHDx5g7dq1+P3337Fnzx6o1WoMGzYMYWFhcHR0hL29PcaOHQs/Pz+DF4ICDDSIiIgUpcSPqt25cweDBw/G7du3oVarUbduXezZswcdOnQAAMyfPx9mZmYIDAyEVqtFQEAAli5dWqy+eB0NIgLA62gQ5ackrqNx7eF22drytO0qW1tyYUaDiIhIQab+WycMNIiIiBSkxNRJSeJZJ0RERGQ0zGgQEREpyMQTGgw0iIiIlGTIr66+jBhoEBERKcjE4wyu0SAiIiLjYUaDiIhIQXL+THxpxECDiIhIQZw6ISIiIiomZjSIiIgUZOoX7GKgQUREpCATjzM4dUJERETGw4wGERGRgkz9Gz8DDSIiIgWZ+hoNUw+kiIiISEHMaBARESnKtFMaDDSIiIgUJDHQICIiImORJNNexWDae0dERESKYkaDiIhIUZw6ISIiIiMx9TUanDohIiIio2FGg4iISFGmndFgoEFERKQgnnVCREREVEzMaBARESmKUydERERkJDzrhIiIiKiYmNEgIiJSkKlnNBhoEBERKcq0JxcYaBARESlIkkw7o2HaYRQREREpihkNIiIiRZl2RoOBBhERkYJMfTEop06IiIheMRqNBo0aNYKdnR1cXFzQo0cPxMbG6tXJyMhASEgInJycYGtri8DAQCQkJBjcFwMNIiIiRZnJuBVNdHQ0QkJCcPjwYezduxdZWVl48803kZaWpqsTGhqK7du3Y8OGDYiOjsatW7fQq1cvg/dOEkIIg+/10juv9ACISp3JR28oPQSiUieicTuj95H++C/Z2rIu06xY97t79y5cXFwQHR2NVq1aISUlBc7Ozli7di169+4NADh37hxq1KiBQ4cOoWnTpkVumxkNIiIiE6HVapGamqq3abXaQu+XkpICAHB0dAQAxMTEICsrC/7+/ro6Pj4+qFSpEg4dOmTQmBhoEBERKUiSJNk2jUYDtVqtt2k0muf2n5OTgwkTJqB58+aoXbs2ACA+Ph6WlpZwcHDQq+vq6or4+HiD9o9nnRARESlKvrNOwsPDERYWplemUqmee5+QkBCcPn0aBw8elG0cT2OgQUREZCJUKlWhgcXTxowZgx07duDAgQN47bXXdOVubm7IzMxEcnKyXlYjISEBbm5uBo2JUydEREQKkmAm21ZUQgiMGTMGP//8M/bv3w8vLy+92319fWFhYYGoqChdWWxsLOLi4uDn52fQ/jGjQUREpKiSv2BXSEgI1q5di61bt8LOzk637kKtVsPa2hpqtRrDhg1DWFgYHB0dYW9vj7Fjx8LPz8+gM04ABhpERESKUuJH1ZYtWwYAaNOmjV55ZGQkgoODAQDz58+HmZkZAgMDodVqERAQgKVLlxrcF6+jQUQAeB0NovyUxHU0MnOOy9aWpVlD2dqSCzMaREREijLt3zphoEFERKQgQxZxvoxMe++IiIhIUcxoEBERKYpTJ0RERGQkkokHGpw6ISIiIqNhRoOIiEhBSlxHoyQx0CAiIlKUaU8umPbeERERkaKY0SAiIlKQqS8GZaBBRESkKAYaREREZCSmvhiUazSIiIjIaJjRICIiUpRpf+dnoEFERKQgU18MatphFBERESlKEkIIpQdBryatVguNRoPw8HCoVCqlh0NUKvB1QaaGgQYpJjU1FWq1GikpKbC3t1d6OESlAl8XZGo4dUJERERGw0CDiIiIjIaBBhERERkNAw1SjEqlwscff8wFb0RP4euCTA0XgxIREZHRMKNBRERERsNAg4iIiIyGgQYREREZDQMNIiIiMhoGGqSIJUuWoHLlyrCyskKTJk1w9OhRpYdEpKgDBw6ga9eu8PDwgCRJ2LJli9JDIpIFAw0qcevWrUNYWBg+/vhjnDhxAvXq1UNAQADu3Lmj9NCIFJOWloZ69ephyZIlSg+FSFY8vZVKXJMmTdCoUSMsXrwYAJCTk4OKFSti7Nix+OCDDxQeHZHyJEnCzz//jB49eig9FKIXxowGlajMzEzExMTA399fV2ZmZgZ/f38cOnRIwZEREZExMNCgEpWYmIjs7Gy4urrqlbu6uiI+Pl6hURERkbEw0CAiIiKjYaBBJap8+fIwNzdHQkKCXnlCQgLc3NwUGhURERkLAw0qUZaWlvD19UVUVJSuLCcnB1FRUfDz81NwZEREZAxllB4AvXrCwsIQFBSEhg0bonHjxliwYAHS0tIwZMgQpYdGpJiHDx/i4sWLur+vXLmCkydPwtHREZUqVVJwZEQvhqe3kiIWL16MefPmIT4+HvXr18fChQvRpEkTpYdFpJjff/8dbdu2zVMeFBSEVatWlfyAiGTCQIOIiIiMhms0iIiIyGgYaBAREZHRMNAgIiIio2GgQUREREbDQIOIiIiMhoEGERERGQ0DDSIiIjIaBhpEr6Dg4GD06NFD93ebNm0wYcKEEh/H77//DkmSkJycXOJ9E1HJYKBBVIoEBwdDkiRIkgRLS0tUq1YNn3zyCR4/fmzUfjdv3oxPP/20SHUZHBCRIfhbJ0SlTMeOHREZGQmtVoudO3ciJCQEFhYWCA8P16uXmZkJS0tLWfp0dHSUpR0iomcxo0FUyqhUKri5ucHT0xOjRo2Cv78/tm3bppvumDVrFjw8PFC9enUAwPXr19G3b184ODjA0dER3bt3x9WrV3XtZWdnIywsDA4ODnBycsLkyZPx7C8PPDt1otVqMWXKFFSsWBEqlQrVqlXDypUrcfXqVd3vcZQrVw6SJCE4OBjAk1/h1Wg08PLygrW1NerVq4eNGzfq9bNz5068/vrrsLa2Rtu2bfXGSUSmiYEGUSlnbW2NzMxMAEBUVBRiY2Oxd+9e7NixA1lZWQgICICdnR3++OMP/Pnnn7C1tUXHjh119/n888+xatUqfPvttzh48CDu3buHn3/++bl9Dh48GD/++CMWLlyIs2fPYsWKFbC1tUXFihWxadMmAEBsbCxu376NL7/8EgCg0Wjw3XffYfny5fjvv/8QGhqKt99+G9HR0QCeBES9evVC165dcfLkSQwfPhwffPCBsR42IiotBBGVGkFBQaJ79+5CCCFycnLE3r17hUqlEhMnThRBQUHC1dVVaLVaXf01a9aI6tWri5ycHF2ZVqsV1tbWYs+ePUIIIdzd3UVERITu9qysLPHaa6/p+hFCiNatW4vx48cLIYSIjY0VAMTevXvzHeNvv/0mAIj79+/ryjIyMkTZsmXFX3/9pVd32LBhYsCAAUIIIcLDw0XNmjX1bp8yZUqetojItHCNBlEps2PHDtja2iIrKws5OTkYOHAgpk+fjpCQENSpU0dvXcapU6dw8eJF2NnZ6bWRkZGBS5cuISUlBbdv30aTJk10t5UpUwYNGzbMM32S6+TJkzA3N0fr1q2LPOaLFy/i0aNH6NChg155ZmYm3njjDQDA2bNn9cYBAH5+fkXug4heTgw0iEqZtm3bYtmyZbC0tISHhwfKlPnfy9TGxkav7sOHD+Hr64sffvghTzvOzs7F6t/a2trg+zx8+BAA8Msvv6BChQp6t6lUqmKNg4hMAwMNolLGxsYG1apVK1LdBg0aYN26dXBxcYG9vX2+ddzd3XHkyBG0atUKAPD48WPExMSgQYMG+davU6cOcnJyEB0dDX9//zy352ZUsrOzdWU1a9aESqVCXFxcgZmQGjVqYNu2bXplhw8fLnwnieilxsWgRC+xQYMGoXz58ujevTv++OMPXLlyBb///jvGjRuHGzduAADGjx+POXPmYMuWLTh37hxGjx793GtgVK5cGUFBQRg6dCi2bNmia3P9+vUAAE9PT0iShB07duDu3bt4+PAh7OzsMHHiRISGhmL16tW4dOkSTpw4gUWLFmH16tUAgPfeew8XLlzApEmTEBsbi7Vr12LVqlXGfoiISGEMNIheYmXLlsWBAwdQqVIl9OrVCzVq1MCwYcOQkZGhy3C8//77eOeddxAUFAQ/Pz/Y2dmhZ8+ez2132bJl6N27N0aPHg0fHx+MGDECaWlpAIAKFSpgxowZ+OCDD+Dq6ooxY8YAAD799FNMnToVGo0GNWrUQMeOHfHLL7/Ay8sLAFCpUiVs2rQJW7ZsQb169bB8+XLMnj3biI8OEZUGkihoRRgRERHRC2JGg4iIiIyGgQYREREZDQMNIiIiMhoGGkRERGQ0DDSIiIjIaBhoEBERkdEw0CAiIiKjYaBBRERERsNAg4iIiIyGgQYREREZDQMNIiIiMhoGGkRERGQ0/w/ZoEytv6hHAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation metrics - Confusion Matrix\n",
    "confusion_matrix = metrics.confusion_matrix(X_test_prediction, y_data_test_set) \n",
    "\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g', cmap=\"YlGnBu\")\n",
    "plt.title(\"Model confusion matrix for survival on Titanic (testing data)\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual');\n",
    "\n",
    "print(\"Shape of CM:\\nTrue Negative || False Negative \\nFalse Positive || True Positive\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2076fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of testing data: 0.7988826815642458\n",
      "Precision and Recall + F1 Score Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       111\n",
      "           1       0.76      0.69      0.72        68\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.79      0.78      0.78       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "ROC-AUC score: 0.7780206677265501\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics \n",
    "# Accuracy\n",
    "testing_data_accuracy = sklearn.metrics.accuracy_score(y_data_test_set,X_test_prediction)\n",
    "print(\"Accuracy score of testing data:\",testing_data_accuracy)\n",
    "\n",
    "# Precision and Recall + F1 Score\n",
    "print(\"Precision and Recall + F1 Score Report:\")\n",
    "print(classification_report(y_data_test_set,X_test_prediction))\n",
    "\n",
    "    #print(sklearn.metrics.precision_recall_fscore_support(y_data_test_set,X_test_prediction))\n",
    "\n",
    "# ROC_AUC score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"ROC-AUC score:\",sklearn.metrics.roc_auc_score(y_data_test_set,X_test_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128d193",
   "metadata": {},
   "source": [
    "### Processing of Final Testing data - from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d32f6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_testing_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a75388ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40be125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "final_testing_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9015d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_testing_data_proc = pipeline.fit_transform(final_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd722d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>27.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>30.27259</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass       Age  SibSp  Parch      Fare    C    S    Q  \\\n",
       "0            892       3  34.50000      0      0    7.8292  0.0  1.0  0.0   \n",
       "1            893       3  47.00000      1      0    7.0000  0.0  0.0  1.0   \n",
       "2            894       2  62.00000      0      0    9.6875  0.0  1.0  0.0   \n",
       "3            895       3  27.00000      0      0    8.6625  0.0  0.0  1.0   \n",
       "4            896       3  22.00000      1      1   12.2875  0.0  0.0  1.0   \n",
       "..           ...     ...       ...    ...    ...       ...  ...  ...  ...   \n",
       "413         1305       3  30.27259      0      0    8.0500  0.0  0.0  1.0   \n",
       "414         1306       1  39.00000      0      0  108.9000  1.0  0.0  0.0   \n",
       "415         1307       3  38.50000      0      0    7.2500  0.0  0.0  1.0   \n",
       "416         1308       3  30.27259      0      0    8.0500  0.0  0.0  1.0   \n",
       "417         1309       3  30.27259      1      1   22.3583  1.0  0.0  0.0   \n",
       "\n",
       "     Female  Male  \n",
       "0       0.0   1.0  \n",
       "1       1.0   0.0  \n",
       "2       0.0   1.0  \n",
       "3       0.0   1.0  \n",
       "4       1.0   0.0  \n",
       "..      ...   ...  \n",
       "413     0.0   1.0  \n",
       "414     1.0   0.0  \n",
       "415     0.0   1.0  \n",
       "416     0.0   1.0  \n",
       "417     0.0   1.0  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_testing_data_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30d13262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Pclass, Age, SibSp, Parch, Fare, C, S, Q, Female, Male]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking for another NaN after pipline preprocessing:\n",
    "final_testing_data_proc[final_testing_data_proc[\"Fare\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "913e8d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index of the rows with nan determined:\n",
    "final_testing_data_proc[final_testing_data_proc['Fare'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb5a4b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# dropping the rows with nulls\n",
    "index_fare_nan = final_testing_data_proc[final_testing_data_proc['Fare'].isnull()].index.tolist()\n",
    "\n",
    "index_fare_nan_str = [str(x) for x in index_fare_nan]\n",
    "print(index_fare_nan_str)\n",
    "\n",
    "\n",
    "update_final_testing_data_proc = final_testing_data_proc.drop(index_fare_nan,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0163cb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>C</th>\n",
       "      <th>S</th>\n",
       "      <th>Q</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Pclass, Age, SibSp, Parch, Fare, C, S, Q, Female, Male]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_final_testing_data_proc[final_testing_data_proc[\"Fare\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a7bc815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_final_testing_data_proc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca05acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next step - we want to have numpy array from the df, so we transform them:\n",
    "\n",
    "# final testing data are not labeled, therefore we dont need to split dataset to \"x\" and \"y\" part\n",
    "# X = final_testing_data_proc\n",
    "# y = final_testing_data_proc[\"Survived\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_data_final_test = scaler.fit_transform(update_final_testing_data_proc)\n",
    "# y_data_final_test = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "601da7f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is there some another NULL?\n",
    "np.unique(np.isnan(X_data_final_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99e743",
   "metadata": {},
   "source": [
    "###  Final Deploy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c2b75ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "my_final_test_prediction = model.predict(X_data_final_test) \n",
    "print(my_final_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c906a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final saving predition into csv --> for upload to kaggle :)\n",
    "final_df = pd.DataFrame(final_testing_data[\"PassengerId\"])\n",
    "final_df[\"Survived\"] = my_final_test_prediction\n",
    "final_df.to_csv(\"prediction_LR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d31af15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
